{"paragraphs":[{"text":"%md\n----\nWhen you open this sample notebook for the first time, you will see a **Settings** section at the start. You must click **Save** in the section so that the interpreters can be bound to this notebook.","dateUpdated":"2016-09-27T00:07:58+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/scala","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr />\n<p>When you open this sample notebook for the first time, you will see a <strong>Settings</strong> section at the start. You must click <strong>Save</strong> in the section so that the interpreters can be bound to this notebook.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<p>When you open this sample notebook for the first time, you will see a <strong>Settings</strong> section at the start. You must click <strong>Save</strong> in the section so that the interpreters can be bound to this notebook.</p>\n"},"apps":[],"jobName":"paragraph_1474673466895_-365179343","id":"20160923-233106_1870241345","dateCreated":"2016-09-23T11:31:06+0000","dateStarted":"2016-09-27T00:07:57+0000","dateFinished":"2016-09-27T00:07:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:11515"},{"text":"%md\n----------\n## Notebook setup\n\nWhen using PySpark kernel notebooks on HDInsight, there is no need to create a SparkContext or a SparkSession; those are all created for you automatically when you run the first code cell, and you'll be able to see the progress printed. The contexts are created with the following variable names:\n- SparkSession (spark)\n\nTo run the cells below, place the cursor in the cell and then press **SHIFT + ENTER**.","dateUpdated":"2016-09-23T06:07:41+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr />\n<h2>Notebook setup</h2>\n<p>When using PySpark kernel notebooks on HDInsight, there is no need to create a SparkContext or a SparkSession; those are all created for you automatically when you run the first code cell, and you'll be able to see the progress printed. The contexts are created with the following variable names:</p>\n<ul>\n<li>SparkSession (spark)</li>\n</ul>\n<p>To run the cells below, place the cursor in the cell and then press <strong>SHIFT + ENTER</strong>.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h2>Notebook setup</h2>\n<p>When using PySpark kernel notebooks on HDInsight, there is no need to create a SparkContext or a SparkSession; those are all created for you automatically when you run the first code cell, and you'll be able to see the progress printed. The contexts are created with the following variable names:</p>\n<ul>\n<li>SparkSession (spark)</li>\n</ul>\n<p>To run the cells below, place the cursor in the cell and then press <strong>SHIFT + ENTER</strong>.</p>\n"},"apps":[],"jobName":"paragraph_1474650712024_951811659","id":"20160923-171152_67224835","dateCreated":"2016-09-23T05:11:52+0000","dateStarted":"2016-09-23T06:07:41+0000","dateFinished":"2016-09-23T06:07:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11516"},{"text":"%md\n--------\n\n## Save raw data as a Hive table\n\nLoad sample data into a temporary table. We use a sample data file, **hvac.csv**. When you provision a Spark cluster in HDInsight, the sample data file, **hvac.csv**, is copied to the associated storage account under **\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac**.","dateUpdated":"2016-09-23T06:07:46+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr />\n<h2>Save raw data as a Hive table</h2>\n<p>Load sample data into a temporary table. We use a sample data file, <strong>hvac.csv</strong>. When you provision a Spark cluster in HDInsight, the sample data file, <strong>hvac.csv</strong>, is copied to the associated storage account under <strong>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac</strong>.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h2>Save raw data as a Hive table</h2>\n<p>Load sample data into a temporary table. We use a sample data file, <strong>hvac.csv</strong>. When you provision a Spark cluster in HDInsight, the sample data file, <strong>hvac.csv</strong>, is copied to the associated storage account under <strong>\\HdiSamples\\HdiSamples\\SensorSampleData\\hvac</strong>.</p>\n"},"apps":[],"jobName":"paragraph_1474650732251_420873501","id":"20160923-171212_627726630","dateCreated":"2016-09-23T05:12:12+0000","dateStarted":"2016-09-23T06:07:46+0000","dateFinished":"2016-09-23T06:07:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11517"},{"text":"%livy.spark\n\n// Create an RDD from sample data\nval hvacText = spark.sparkContext.textFile(\"/HdiSamples/HdiSamples/SensorSampleData/hvac/HVAC.csv\")\n\ncase class HVACRow(\n        Date: String,\n        Time: String,\n        TargetTemp: Integer,\n        ActualTemp: Integer,\n        BuildingID: Integer)\n\nval hvacTable = hvacText.map(s => s.split(\",\")).\n                            filter(s => s(0) != \"Date\").     // filter out the line with column names\n                            map( s => HVACRow(s(0), s(1), s(2).toInt, s(3).toInt, s(6).toInt)).toDF()\nhvacTable.write.mode(\"overwrite\").saveAsTable(\"hvac\")","dateUpdated":"2016-09-23T06:05:44+0000","config":{"colWidth":8,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/text","results":{},"editorSetting":{"language":"text","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1474651450554_2040168895","id":"20160923-172410_797408006","dateCreated":"2016-09-23T05:24:10+0000","dateStarted":"2016-09-23T05:57:39+0000","dateFinished":"2016-09-23T05:57:57+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11518"},{"text":"%md\nVerify that the table was successfully created. You can use the `%livy.sql` directive to run HiveQL commands inline in the cell.","dateUpdated":"2016-09-23T06:07:49+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Verify that the table was successfully created. You can use the <code>%livy.sql</code> directive to run HiveQL commands inline in the cell.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<p>Verify that the table was successfully created. You can use the <code>%livy.sql</code> directive to run HiveQL commands inline in the cell.</p>\n"},"apps":[],"jobName":"paragraph_1474653527574_531325439","id":"20160923-175847_1410356566","dateCreated":"2016-09-23T05:58:47+0000","dateStarted":"2016-09-23T06:07:49+0000","dateFinished":"2016-09-23T06:07:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11519"},{"text":"%livy.sql\nSHOW TABLES\n","dateUpdated":"2016-09-23T06:06:05+0000","config":{"colWidth":8,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/text","results":{},"editorSetting":{"language":"text","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1474651511809_2021159668","id":"20160923-172511_1661563629","dateCreated":"2016-09-23T05:25:11+0000","dateStarted":"2016-09-23T05:59:21+0000","dateFinished":"2016-09-23T05:59:22+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11520"},{"text":"%md\n----\nOnly the tables that have false under the `isTemporary` column are Hive tables that will be stored in the metastore and can be accessed from the BI tools. In this tutorial, we will connect to the `hvac` table we just created.\n\nVerify that the table contains the intended data. Retrieve a sample dataset from the table.","dateUpdated":"2016-09-23T06:07:52+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr />\n<p>Only the tables that have false under the <code>isTemporary</code> column are Hive tables that will be stored in the metastore and can be accessed from the BI tools. In this tutorial, we will connect to the <code>hvac</code> table we just created.</p>\n<p>Verify that the table contains the intended data. Retrieve a sample dataset from the table.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<p>Only the tables that have false under the <code>isTemporary</code> column are Hive tables that will be stored in the metastore and can be accessed from the BI tools. In this tutorial, we will connect to the <code>hvac</code> table we just created.</p>\n<p>Verify that the table contains the intended data. Retrieve a sample dataset from the table.</p>\n"},"apps":[],"jobName":"paragraph_1474652906604_1280528950","id":"20160923-174826_719629176","dateCreated":"2016-09-23T05:48:26+0000","dateStarted":"2016-09-23T06:07:52+0000","dateFinished":"2016-09-23T06:07:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11521"},{"text":"%livy.sql\r\nSELECT * FROM hvac LIMIT 10","dateUpdated":"2016-09-23T06:07:18+0000","config":{"colWidth":8,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Date","index":0,"aggr":"sum"}],"values":[{"name":"Time","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Date","index":0,"aggr":"sum"},"yAxis":{"name":"Time","index":1,"aggr":"sum"}}},"enabled":true,"editorMode":"ace/mode/text","tableHide":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1474653804949_1479729833","id":"20160923-180324_787695995","dateCreated":"2016-09-23T06:03:24+0000","dateStarted":"2016-09-23T06:07:06+0000","dateFinished":"2016-09-23T06:07:08+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11522"},{"text":"%md\nYou have now loaded the data from the sample data file into a Hive table.","dateUpdated":"2016-09-23T06:07:55+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>You have now loaded the data from the sample data file into a Hive table.</p>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<p>You have now loaded the data from the sample data file into a Hive table.</p>\n"},"apps":[],"jobName":"paragraph_1474653852821_1797375894","id":"20160923-180412_1524394094","dateCreated":"2016-09-23T06:04:12+0000","dateStarted":"2016-09-23T06:07:55+0000","dateFinished":"2016-09-23T06:07:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11523"},{"text":"%md\n--------\n\n## Use Power BI to analyze data in the Hive table\n\nOnce you have saved the data as a Hive table, you can use Power BI to connect to the data and visualize it to create reports, dashboards, etc.\n\n1. Sign in to [Power BI](http://www.powerbi.com/).\n\n2. On the Welcome screen, click **Databases & More**.\n\n    ![Spark tile on Power BI dashboard](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Get.Data.png \"Spark tile on Power BI dashboard\")\n\n3. On the next screen, click **Spark on Azure HDInsight** and then click **Connect**. When prompted, enter the cluster URL (`mysparkcluster.azurehdinsight.net`) and the credentials to connect to the cluster. After the connection is established, Power BI starts importing data from the Spark cluster on HDInsight.\n\n4. Power BI imports the data and adds a new Spark dataset under the **Datasets** heading. Click the data set to open a new worksheet to visualize the data. You can also save the worksheet as a report. To save a worksheet, from the **File** menu, click **Save**.\n\n    ![Spark tile on Power BI dashboard](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Tile.png \"Spark tile on Power BI dashboard\")\n    \n5. Notice that the **Fields** list on the right lists the **hvac** table you created earlier. Expand the table to see the fields in the table, as you defined in notebook earlier.\n\n    ![List Hive tables](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Display.Tables.png \"List Hive tables\")\n      \n7. Build a visualization to show the variance between target temperature and actual temperature for each building. Select **Area Chart** (shown in red box) to visualize your data. To define the axis, drag-and-drop the **BuildingID** field under **Axis**, and **ActualTemp**/**TargetTemp** fields under **Value**.\n\n    ![Create visualizations](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.1.png \"Create visualizations\")\n\n8. By default the visualization shows the sum for **ActualTemp** and **TargetTemp**. For both the fields, from the drop-down, select **Average** to get an average of actual and target temperatures for both buildings.\n\n    ![Create visualizations](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.2.png \"Create visualizations\")\n\n9. Your data visualization should be similar to the following. Move your cursor over the visualization to get tool tips with relevant data.\n\n    ![Create visualizations](https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.3.png \"Create visualizations\")\n\n10. Click **Save** from the top menu and provide a report name. You can also pin the visual. When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance.\n\n    You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data. Also, Spark clusters on HDInsight are connected to Power BI with direct connect. This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.","dateUpdated":"2016-09-23T06:08:01+0000","config":{"colWidth":8,"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"editorSetting":{}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<hr />\n<h2>Use Power BI to analyze data in the Hive table</h2>\n<p>Once you have saved the data as a Hive table, you can use Power BI to connect to the data and visualize it to create reports, dashboards, etc.</p>\n<ol>\n<li><p>Sign in to <a href=\"http://www.powerbi.com/\">Power BI</a>.</p>\n</li>\n<li><p>On the Welcome screen, click <strong>Databases &amp; More</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Get.Data.png\" alt=\"Spark tile on Power BI dashboard\" title=\"Spark tile on Power BI dashboard\" /></p>\n</li>\n<li><p>On the next screen, click <strong>Spark on Azure HDInsight</strong> and then click <strong>Connect</strong>. When prompted, enter the cluster URL (<code>mysparkcluster.azurehdinsight.net</code>) and the credentials to connect to the cluster. After the connection is established, Power BI starts importing data from the Spark cluster on HDInsight.</p>\n</li>\n<li><p>Power BI imports the data and adds a new Spark dataset under the <strong>Datasets</strong> heading. Click the data set to open a new worksheet to visualize the data. You can also save the worksheet as a report. To save a worksheet, from the <strong>File</strong> menu, click <strong>Save</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Tile.png\" alt=\"Spark tile on Power BI dashboard\" title=\"Spark tile on Power BI dashboard\" /></p>\n</li>\n<li><p>Notice that the <strong>Fields</strong> list on the right lists the <strong>hvac</strong> table you created earlier. Expand the table to see the fields in the table, as you defined in notebook earlier.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Display.Tables.png\" alt=\"List Hive tables\" title=\"List Hive tables\" /></p>\n</li>\n<li><p>Build a visualization to show the variance between target temperature and actual temperature for each building. Select <strong>Area Chart</strong> (shown in red box) to visualize your data. To define the axis, drag-and-drop the <strong>BuildingID</strong> field under <strong>Axis</strong>, and <strong>ActualTemp</strong>/<strong>TargetTemp</strong> fields under <strong>Value</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.1.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>By default the visualization shows the sum for <strong>ActualTemp</strong> and <strong>TargetTemp</strong>. For both the fields, from the drop-down, select <strong>Average</strong> to get an average of actual and target temperatures for both buildings.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.2.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>Your data visualization should be similar to the following. Move your cursor over the visualization to get tool tips with relevant data.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.3.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>Click <strong>Save</strong> from the top menu and provide a report name. You can also pin the visual. When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance.</p>\n<p>You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data. Also, Spark clusters on HDInsight are connected to Power BI with direct connect. This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.</p>\n</li>\n</ol>\n"}]},"result":{"code":"SUCCESS","type":"HTML","msg":"<hr />\n<h2>Use Power BI to analyze data in the Hive table</h2>\n<p>Once you have saved the data as a Hive table, you can use Power BI to connect to the data and visualize it to create reports, dashboards, etc.</p>\n<ol>\n<li><p>Sign in to <a href=\"http://www.powerbi.com/\">Power BI</a>.</p>\n</li>\n<li><p>On the Welcome screen, click <strong>Databases &amp; More</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Get.Data.png\" alt=\"Spark tile on Power BI dashboard\" title=\"Spark tile on Power BI dashboard\" /></p>\n</li>\n<li><p>On the next screen, click <strong>Spark on Azure HDInsight</strong> and then click <strong>Connect</strong>. When prompted, enter the cluster URL (<code>mysparkcluster.azurehdinsight.net</code>) and the credentials to connect to the cluster. After the connection is established, Power BI starts importing data from the Spark cluster on HDInsight.</p>\n</li>\n<li><p>Power BI imports the data and adds a new Spark dataset under the <strong>Datasets</strong> heading. Click the data set to open a new worksheet to visualize the data. You can also save the worksheet as a report. To save a worksheet, from the <strong>File</strong> menu, click <strong>Save</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Tile.png\" alt=\"Spark tile on Power BI dashboard\" title=\"Spark tile on Power BI dashboard\" /></p>\n</li>\n<li><p>Notice that the <strong>Fields</strong> list on the right lists the <strong>hvac</strong> table you created earlier. Expand the table to see the fields in the table, as you defined in notebook earlier.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Display.Tables.png\" alt=\"List Hive tables\" title=\"List Hive tables\" /></p>\n</li>\n<li><p>Build a visualization to show the variance between target temperature and actual temperature for each building. Select <strong>Area Chart</strong> (shown in red box) to visualize your data. To define the axis, drag-and-drop the <strong>BuildingID</strong> field under <strong>Axis</strong>, and <strong>ActualTemp</strong>/<strong>TargetTemp</strong> fields under <strong>Value</strong>.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.1.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>By default the visualization shows the sum for <strong>ActualTemp</strong> and <strong>TargetTemp</strong>. For both the fields, from the drop-down, select <strong>Average</strong> to get an average of actual and target temperatures for both buildings.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.2.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>Your data visualization should be similar to the following. Move your cursor over the visualization to get tool tips with relevant data.</p>\n<p><img src=\"https://mysstorage.blob.core.windows.net/notebookimages/sparkbi/HDI.Spark.PowerBI.Visual.3.png\" alt=\"Create visualizations\" title=\"Create visualizations\" /></p>\n</li>\n<li><p>Click <strong>Save</strong> from the top menu and provide a report name. You can also pin the visual. When you pin a visualization, it will be stored on your dashboard so you can track the latest value at a glance.</p>\n<p>You can add as many visualizations as you want for the same dataset and pin them to the dashboard for a snapshot of your data. Also, Spark clusters on HDInsight are connected to Power BI with direct connect. This means that Power BI always has the most up-to-date from your cluster so you do not need to schedule refreshes for the dataset.</p>\n</li>\n</ol>\n"},"apps":[],"jobName":"paragraph_1474653882389_1631595090","id":"20160923-180442_515505811","dateCreated":"2016-09-23T06:04:42+0000","dateStarted":"2016-09-23T06:08:01+0000","dateFinished":"2016-09-23T06:08:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:11524"},{"dateUpdated":"2016-09-23T06:07:33+0000","config":{"colWidth":8,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1474653903237_1340355497","id":"20160923-180503_1370375763","dateCreated":"2016-09-23T06:05:03+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:11525"}],"name":"/Scala/04 - Use BI tools with Apache Spark on HDInsight","id":"2BX3YB5ZQ","angularObjects":{"2BW4JER6M:shared_process":[],"2BY6DUW66:shared_process":[],"2BVQBY2TK:shared_process":[],"2BWAGF2BV:shared_process":[],"2BW5W61RX:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}